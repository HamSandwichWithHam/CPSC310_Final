{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afff3c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and classes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a41e027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digits = pd.read_csv('../mnist.csv')\n",
    "df_digits.head()\n",
    "\n",
    "X = df_digits[df_digits.columns[:-1]].to_numpy()\n",
    "y = df_digits[df_digits.columns[-1]].to_numpy()\n",
    "\n",
    "train = 5000\n",
    "val = 60000\n",
    "\n",
    "\n",
    "#Split the data as in Assignment #3\n",
    "X_train, X_val, X_test = X[:train], X[train:val], X[val:]\n",
    "y_train, y_val, y_test = y[:train], y[train:val], y[val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a062e834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.45 s\n",
      "Wall time: 649 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#going to try to improve my SVC classifier from Assignment #3 with bagging\n",
    "#the SVC classifier performed best with the MNIST data reduced to 150 features.\n",
    "\n",
    "preprocess_pipeline = Pipeline([('StandardScaler', StandardScaler()), ('Binarizer', Binarizer())])\n",
    "\n",
    "\n",
    "preprocess_pipeline_reduced = Pipeline([('StandardScaler', StandardScaler()), ('Binarizer', Binarizer()),\n",
    "                                        ('Principle Compnent Analysis', PCA(n_components=150))])\n",
    "\n",
    "X_train_proc = preprocess_pipeline.fit_transform(X_train)\n",
    "\n",
    "X_train_proc_reduced = preprocess_pipeline_reduced.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09af3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC classifier using optimized paramters from Assignment #3 plus probability set True so the bagging \n",
    "#classifier can use soft voting.\n",
    "\n",
    "svm_clf = SVC(gamma='scale', kernel='poly', probability=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f220aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a baseline set of accuracy scores\n",
    "print('one SVC', cross_val_score(svm_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#one SVC [0.98025  0.978375 0.98     0.97725  0.98    ]\n",
    "#CPU times: total: 13.7 s\n",
    "#Wall time: 11min 55s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f351ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#create BaggingClassifier\n",
    "bag_clf = BaggingClassifier(svm_clf, n_estimators=50, max_samples=1000, random_state=42, n_jobs=-1)\n",
    "\n",
    "print('bagging SVC', cross_val_score(bag_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#bagging SVC [0.94725  0.939875 0.9465   0.9385   0.945   ]\n",
    "#CPU times: total: 93.8 ms\n",
    "#Wall time: 2min 19s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#increase max samples.  Better, but 12 times the time for 5 times the samples.  Still not as good \n",
    "#as just one pass on the full training set.  What about increasing the estimators by 10x while\n",
    "#keeping the samples small.\n",
    "\n",
    "bag_clf = BaggingClassifier(svm_clf, n_estimators=50, max_samples=5000, random_state=42, n_jobs=-1)\n",
    "\n",
    "print('bagging SVC', cross_val_score(bag_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#bagging SVC [0.967625 0.95975  0.967375 0.9605   0.964   ]\n",
    "#CPU times: total: 109 ms\n",
    "#Wall time: 25min 20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31fff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bag_clf = BaggingClassifier(svm_clf, n_estimators=500, max_samples=1000, random_state=42, n_jobs=-1)\n",
    "\n",
    "print('bagging SVC', cross_val_score(bag_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#bagging SVC [0.948125 0.939    0.947125 0.937    0.944875]\n",
    "#CPU times: total: 125 ms\n",
    "#Wall time: 22min 21s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0feebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#try boosting.  Check the time on 3 estimators.  It seems it should be n_estimators * the basline 11 \n",
    "#minutes above.\n",
    "\n",
    "#so worse.  Overfitting?  Try fitting to the training set and predicting on that.\n",
    "\n",
    "ada_clf = AdaBoostClassifier(svm_clf, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "\n",
    "print('AdaBoosting SVC', cross_val_score(ada_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "###remember that you didn't do much in the way of data reduction optimization in Assignment #3\n",
    "\n",
    "ada_clf.fit(X_train_proc_reduced, y_train)\n",
    "y_hat = ada_clf.predict(X_train_proc_reduced)\n",
    "print('accuracy', accuracy_score(y_train, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c94689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one SVC [0.945 0.95  0.956 0.963 0.956]\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Generate a baseline set of accuracy scores using 5000 instances in the training set\n",
    "print('one SVC', cross_val_score(svm_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#one SVC [0.945 0.95  0.956 0.963 0.956]\n",
    "#CPU times: total: 93.8 ms\n",
    "#Wall time: 13.7 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92b43b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting SVC [0.85  0.861 0.863 0.874 0.836]\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#AdaBoost with 5000 instances of training set\n",
    "ada_clf = AdaBoostClassifier(svm_clf, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "\n",
    "print('AdaBoosting SVC', cross_val_score(ada_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#AdaBoosting SVC [0.85  0.861 0.863 0.874 0.836]\n",
    "#CPU times: total: 62.5 ms\n",
    "#Wall time: 1min 27s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "654c2ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting SVC [0.728 0.71  0.79  0.522 0.53 ]\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 5min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#AdaBoost with 5000 instances of training set\n",
    "ada_clf = AdaBoostClassifier(svm_clf, n_estimators=10, learning_rate=0.5, random_state=42)\n",
    "\n",
    "print('AdaBoosting SVC', cross_val_score(ada_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#AdaBoosting SVC [0.728 0.71  0.79  0.522 0.53 ]\n",
    "#CPU times: total: 15.6 ms\n",
    "#Wall time: 5min 27s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68dee2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting DTS [0.658 0.663 0.628 0.675 0.519]\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#try AdaBoost with a Decision stump like in the book\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=50, learning_rate=0.5, \n",
    "                            random_state=42)\n",
    "\n",
    "print('AdaBoosting DTS', cross_val_score(ada_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "#AdaBoosting DTS [0.658 0.663 0.628 0.675 0.519]\n",
    "#CPU times: total: 93.8 ms\n",
    "#Wall time: 16.1 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce589da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTS [0.2   0.201 0.202 0.211 0.206]\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 428 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#try Decision stump alone\n",
    "print('DTS', cross_val_score(DecisionTreeClassifier(max_depth=1), X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#DTS [0.2   0.201 0.202 0.211 0.206]\n",
    "#CPU times: total: 15.6 ms\n",
    "#Wall time: 428 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c536ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting DTS [0.62  0.497 0.648 0.616 0.474]\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=500, learning_rate=0.5, \n",
    "                            random_state=42)\n",
    "\n",
    "print('AdaBoosting DTS', cross_val_score(ada_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#AdaBoosting DTS [0.62  0.497 0.648 0.616 0.474]\n",
    "#CPU times: total: 31.2 ms\n",
    "#Wall time: 3min 11s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59ef2280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting DTS [0.674 0.673 0.705 0.74  0.698]\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#so is the stump because it the book example only had two classes? A max depth of 4 accomodates up \n",
    "#to 16 classes and there are 10 digits\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4), n_estimators=50, learning_rate=0.5, \n",
    "                            random_state=42)\n",
    "\n",
    "print('AdaBoosting DTS', cross_val_score(ada_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#AdaBoosting DTS [0.674 0.673 0.705 0.74  0.698]\n",
    "#CPU times: total: 78.1 ms\n",
    "#Wall time: 1min 7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fb77d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTS [0.569 0.569 0.579 0.583 0.575]\n"
     ]
    }
   ],
   "source": [
    "#how about a 16 leaf decision tree baseline\n",
    "\n",
    "print('DTS', cross_val_score(DecisionTreeClassifier(max_depth=4), X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#DTS [0.569 0.569 0.579 0.583 0.575]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e54e0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting DTS [0.756 0.719 0.773 0.796 0.753]\n"
     ]
    }
   ],
   "source": [
    "#lower the learning rate\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4), n_estimators=50, learning_rate=0.1, \n",
    "                            random_state=42)\n",
    "\n",
    "print('AdaBoosting DTS', cross_val_score(ada_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45b2e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting SVC [0.794 0.777 0.813 0.815 0.825]\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 6min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#AdaBoost with 5000 instances of training set.  Perhaps my learning rates have been too high.\n",
    "ada_clf = AdaBoostClassifier(svm_clf, n_estimators=10, learning_rate=0.01, random_state=42)\n",
    "\n",
    "print('AdaBoosting SVC', cross_val_score(ada_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#learning rate = 0.1\n",
    "#AdaBoosting SVC [0.875 0.803 0.825 0.886 0.795]\n",
    "#CPU times: total: 31.2 ms\n",
    "#Wall time: 5min 32s\n",
    "\n",
    "#learning rate = 0.01\n",
    "#AdaBoosting SVC [0.794 0.777 0.813 0.815 0.825]\n",
    "#CPU times: total: 46.9 ms\n",
    "#Wall time: 6min 20s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c179abcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params {'learning_rate': 1, 'n_estimators': 500}\n",
      "CPU times: total: 8min 26s\n",
      "Wall time: 1h 24min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#grid search for DecisionTree with depth of 4\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4), random_state=42)\n",
    "\n",
    "param_grid = [{'n_estimators':[10, 50, 100, 500], 'learning_rate':[0.0001, 0.001, 0.01, 0.1, 1]}]\n",
    "\n",
    "gs = GridSearchCV(ada_clf, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "gs.fit(X_train_proc_reduced, y_train)\n",
    "print('best params', gs.best_params_)\n",
    "\n",
    "#best params {'learning_rate': 1, 'n_estimators': 500}\n",
    "#CPU times: total: 8min 26s\n",
    "#Wall time: 1h 24min 26s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84def39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting DTS [0.844 0.862 0.841 0.88  0.835]\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 12min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4), n_estimators=500, learning_rate=1, \n",
    "                            random_state=42)\n",
    "\n",
    "print('AdaBoosting DTS', cross_val_score(ada_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#AdaBoosting DTS [0.844 0.862 0.841 0.88  0.835]\n",
    "#CPU times: total: 46.9 ms\n",
    "#Wall time: 12min 32s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ddf5193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting DTS [0.86  0.86  0.853 0.865 0.837]\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 13min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4), n_estimators=500, learning_rate=2, \n",
    "                            random_state=42)\n",
    "\n",
    "print('AdaBoosting DTS', cross_val_score(ada_clf, X_train_proc_reduced, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#AdaBoosting DTS [0.86  0.86  0.853 0.865 0.837]\n",
    "#CPU times: total: 62.5 ms\n",
    "#Wall time: 13min 2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a90ad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting DTS full features [0.907 0.894 0.912 0.923 0.897]\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "##was using reduced features above, but the RandomForestModel performed better with \n",
    "#the full set of features in Assignment #3.  Try with the full set of features.\n",
    "\n",
    "#better and much faster.  Is the much faster because I just booted this machine up?\n",
    "\n",
    "%%time\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4), n_estimators=500, learning_rate=2, \n",
    "                            random_state=42)\n",
    "\n",
    "print('AdaBoosting DTS full features', cross_val_score(ada_clf, X_train_proc, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#AdaBoosting DTS full features [0.907 0.894 0.912 0.923 0.897]\n",
    "#CPU times: total: 78.1 ms\n",
    "#Wall time: 2min 37s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2150b99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting DTS full features [0.911 0.906 0.916 0.93  0.921]\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#playing a bit with tree depth.  Adding 1 to depth should double the splits and double the time.\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=500, learning_rate=2, \n",
    "                            random_state=42)\n",
    "\n",
    "print('AdaBoosting DTS full features', cross_val_score(ada_clf, X_train_proc, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#AdaBoosting DTS full features [0.911 0.906 0.916 0.93  0.921]\n",
    "#CPU times: total: 78.1 ms\n",
    "#Wall time: 3min 9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "721c8a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting DTS full features depth 6 [0.93  0.921 0.932 0.934 0.925]\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#playing a bit with tree depth.  Adding 1 to depth (6) while I try to look up how to do this \n",
    "#with grid search\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=6), n_estimators=500, learning_rate=2, \n",
    "                            random_state=42)\n",
    "\n",
    "print('AdaBoosting DTS full features depth 6', cross_val_score(ada_clf, X_train_proc, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#AdaBoosting DTS full features depth 6 [0.93  0.921 0.932 0.934 0.925]\n",
    "#CPU times: total: 46.9 ms\n",
    "#Wall time: 3min 41s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "742a6824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting DTS full features depth 7 [0.936 0.931 0.93  0.942 0.941]\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#playing a bit with tree depth.  Adding 1 to depth (7) while I try to look up how to do this \n",
    "#with grid search\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=7), n_estimators=500, learning_rate=2, \n",
    "                            random_state=42)\n",
    "\n",
    "print('AdaBoosting DTS full features depth 7', cross_val_score(ada_clf, X_train_proc, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#AdaBoosting DTS full features depth 7 [0.936 0.931 0.93  0.942 0.941]\n",
    "#CPU times: total: 46.9 ms\n",
    "#Wall time: 4min 4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##I think I figured it out.  Go go stack overflow.\n",
    "param_grid = {'base_estimator__max_depth':[7, 8, 9, 10]}\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators=500, learning_rate=2, \n",
    "                            random_state=42)\n",
    "\n",
    "gs = GridSearchCV(ada_clf, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "gs.fit(X_train_proc, y_train)\n",
    "print('best params', gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b203f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### about three hours of work lost here because save stopped working.  Here's the best classifier that \n",
    "#came out of that.  Training it on the full set might hit the mark.  It was really close in \n",
    "#earlier testing.\n",
    "\n",
    "%%time\n",
    "###double the estimators\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=9), n_estimators=1000, \n",
    "                             learning_rate = 3, random_state=42)\n",
    "\n",
    "print('AdaBoosting DTS', cross_val_score(ada_clf, X_train_proc, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "#AdaBoosting DTS [0.944 0.943 0.942 0.95  0.942]\n",
    "#CPU times: total: 46.9 ms\n",
    "#Wall time: 10min 39s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37cdb2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC [0.915 0.911 0.922 0.919 0.901]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#apparently this thing comes with it's own estimator.  It mentions regression trees.\n",
    "#not bad for a start.  \n",
    "\n",
    "gb_clf = GradientBoostingClassifier(max_depth=9)\n",
    "\n",
    "print('GBC', cross_val_score(gb_clf, X_train_proc, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#GBC [0.915 0.911 0.922 0.919 0.901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78600bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC [0.945 0.928 0.939 0.94  0.944]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hgb_clf = HistGradientBoostingClassifier(max_depth=9, random_state=42)\n",
    "\n",
    "print('GBC', cross_val_score(hgb_clf, X_train_proc, y_train, cv=5, scoring='accuracy', n_jobs=-1))\n",
    "\n",
    "#GBC [0.945 0.928 0.939 0.94  0.944]\n",
    "#pretty nice and fast too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd3f9f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params {'learning_rate': 0.1, 'max_iter': 500}\n",
      "CPU times: total: 11min 33s\n",
      "Wall time: 1h 47min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hgb_clf = HistGradientBoostingClassifier(max_depth=9, random_state=42)\n",
    "\n",
    "param_grid = [{'max_iter':[10, 50, 100, 500], 'learning_rate':[0.0001, 0.001, 0.01, 0.1, 1]}]\n",
    "\n",
    "gs = GridSearchCV(hgb_clf, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "gs.fit(X_train_proc, y_train)\n",
    "print('best params', gs.best_params_)\n",
    "print('best score', gs.best_score_)\n",
    "\n",
    "#best params {'learning_rate': 0.1, 'max_iter': 500}\n",
    "#best score 0.9400000000000001\n",
    "#CPU times: total: 11min 33s\n",
    "#Wall time: 1h 47min 29s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f16cba29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params {'learning_rate': 0.05, 'max_iter': 500}\n",
      "best score 0.942\n",
      "CPU times: total: 18min 54s\n",
      "Wall time: 1h 22min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hgb_clf = HistGradientBoostingClassifier(max_depth=9, random_state=42)\n",
    "\n",
    "param_grid = [{'max_iter':[250, 500, 1000], 'learning_rate':[0.05, 0.1, 0.2, 0.4]}]\n",
    "\n",
    "gs = GridSearchCV(hgb_clf, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "gs.fit(X_train_proc, y_train)\n",
    "print('best params', gs.best_params_)\n",
    "print('best score', gs.best_score_)\n",
    "#best params {'learning_rate': 0.05, 'max_iter': 500}\n",
    "#best score 0.942\n",
    "#CPU times: total: 18min 54s\n",
    "#Wall time: 1h 22min 38s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e44ba7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.942"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "910c901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada full data [0.966125 0.95675  0.960625 0.953875 0.962625]\n",
      "CPU times: total: 1.33 s\n",
      "Wall time: 1h 55min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#try full dataset on best parameters AdaBoost\n",
    "\n",
    "###double the estimators\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=9), n_estimators=1000, \n",
    "                             learning_rate = 3, random_state=42)\n",
    "\n",
    "X_train_full = X[:40000]\n",
    "y_train_full = y[:40000]\n",
    "\n",
    "X_train_full_proc = preprocess_pipeline.fit_transform(X_train_full)\n",
    "\n",
    "print('Ada full data', cross_val_score(ada_clf, X_train_full_proc, y_train_full,cv=5,\n",
    "                                      n_jobs=-1, scoring='accuracy'))\n",
    "\n",
    "#Ada full data [0.966125 0.95675  0.960625 0.953875 0.962625]\n",
    "#CPU times: total: 1.33 s\n",
    "#Wall time: 1h 55min 22s\n",
    "\n",
    "#average = 0.9599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Hist grad boost on full dataset\n",
    "\n",
    "\n",
    "hgb_clf = HistGradientBoostingClassifier(max_depth=9, random_state=42, learning_rate=0.05, max_iter=500)\n",
    "\n",
    "print('GBC_full', cross_val_score(hgb_clf, X_train_full_proc, y_train_full, \n",
    "                                  cv=5, scoring='accuracy', n_jobs=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34547edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
